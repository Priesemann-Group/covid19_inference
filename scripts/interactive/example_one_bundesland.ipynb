{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Priesemann-Group/covid19_inference/blob/pymc4/scripts/interactive/example_one_bundesland.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional (if not cloned i.e. running in colab)\n",
    "# !pip install covid19_inference\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import aesara\n",
    "aesara.config.mode = \"NUMBA\"\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Example for one region (bundesland)\n",
    "Non-hierarchical model using rki data.\n",
    "\n",
    "Runtime ~ 15 min\n",
    "\n",
    "The first thing we need to do is import some essential stuff. Theses have to be installed and are prerequisites.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import aesara\n",
    "import aesara.tensor as at\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to the fun stuff, we import our module!\n",
    "try:\n",
    "    import covid19_inference as cov19\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(\"../../\")\n",
    "    import covid19_inference as cov19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data retrieval\n",
    "\n",
    "The next thing we want to do is (down)load a dataset. We have retrievers for multiple download sources.\n",
    "Documentation can be found [here](https://covid19-inference.readthedocs.io/en/latest/doc/data_retrieval.html).\n",
    "In this example we will use the RKI dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rki = (\n",
    "    cov19.data_retrieval.RKI()\n",
    ")  # One could also parse True to the constructor of the class to force an auto download\n",
    "#rki.download_all_available_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We can now access this downloaded data by the attribute\n",
    "```\n",
    "rki.data\n",
    "```\n",
    "but normally one would use the build in filter methods,\n",
    "these can be found [here](https://covid19-inference.readthedocs.io/en/latest/doc/data_retrieval.html#covid19_inference.data_retrieval.JHU.get_new).\n",
    "\n",
    "Next we retrieve the filtered data from our source in this example we will get all new cases and the total (cumulative) cases for the bundesland \"Sachsen\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = datetime.datetime(2020, 3, 10)  # For the date filter\n",
    "ed = datetime.datetime(2020, 6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [covid19_inference.data_retrieval.retrieval] Successfully loaded Rki.csv.gz from /tmp/covid19_data/, skipping download.\n"
     ]
    }
   ],
   "source": [
    "total_cases_obs = rki.get_total(\n",
    "    value=\"confirmed\", bundesland=\"Sachsen\", data_begin=bd, data_end=ed\n",
    ")\n",
    "new_cases_obs = rki.get_new(\n",
    "    value=\"confirmed\", bundesland=\"Sachsen\", data_begin=bd, data_end=ed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Create the model\n",
    "\n",
    "First we need to set the priors for the change points and other configs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_data_sim = 16  # should be significantly larger than the expected delay, in\n",
    "# order to always fit the same number of data points.\n",
    "num_days_forecast = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the priors for the changepoints here\n",
    "prior_date_mild_dist_begin = datetime.datetime(2020, 3, 9)\n",
    "prior_date_strong_dist_begin = datetime.datetime(2020, 3, 16)\n",
    "prior_date_contact_ban_begin = datetime.datetime(2020, 3, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_points = [\n",
    "    dict(\n",
    "        pr_mean_date_transient=prior_date_mild_dist_begin,\n",
    "        pr_sigma_date_transient=3,\n",
    "        pr_median_lambda=0.2,\n",
    "        pr_sigma_lambda=1,\n",
    "    ),\n",
    "    dict(\n",
    "        pr_mean_date_transient=prior_date_strong_dist_begin,\n",
    "        pr_sigma_date_transient=1.5,\n",
    "        pr_median_lambda=1 / 8,\n",
    "        pr_sigma_lambda=1,\n",
    "    ),\n",
    "    dict(\n",
    "        pr_mean_date_transient=prior_date_contact_ban_begin,\n",
    "        pr_sigma_date_transient=1.5,\n",
    "        pr_median_lambda=1 / 8 / 2,\n",
    "        pr_sigma_lambda=1,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Next, we create the model! There are default values for most of the function arguments,\n",
    "but we will try to explicitly set all kwargs for the sake of this example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_model = dict(\n",
    "    new_cases_obs=new_cases_obs[:],\n",
    "    data_begin=bd,\n",
    "    fcast_len=num_days_forecast,\n",
    "    diff_data_sim=diff_data_sim,\n",
    "    N_population=4e6,\n",
    ")\n",
    "# Median of the prior for the delay in case reporting, we assume 10 days\n",
    "pr_delay = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The model is specified in a context. Each function in this context\n",
    "has access to the model parameters set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [covid19_inference.model.spreading_rate] Lambda_t with sigmoids\n",
      "INFO     [covid19_inference.model.compartmental_models] Uncorrelated prior_I\n",
      "INFO     [covid19_inference.model.compartmental_models] SIR\n",
      "INFO     [covid19_inference.model.delay] Delaying cases\n",
      "INFO     [covid19_inference.model.week_modulation] Week modulation\n"
     ]
    }
   ],
   "source": [
    "with cov19.model.Cov19Model(**params_model) as this_model:\n",
    "    # Create the an array of the time dependent infection rate lambda\n",
    "    lambda_t_log = cov19.model.lambda_t_with_sigmoids(\n",
    "        pr_median_lambda_0=0.4,\n",
    "        pr_sigma_lambda_0=0.5,\n",
    "        change_points_list=change_points,  # The change point priors we constructed earlier\n",
    "        name_lambda_t=\"lambda_t\",  # Name for the variable in the trace (see later)\n",
    "    )\n",
    "\n",
    "    # set prior distribution for the recovery rate\n",
    "    mu = pm.Lognormal(name=\"mu\", mu=np.log(1 / 8), sigma=0.2)\n",
    "\n",
    "    # This builds a decorrelated prior for I_begin for faster inference.\n",
    "    # It is not necessary to use it, one can simply remove it and use the default argument\n",
    "    # for pr_I_begin in cov19.SIR\n",
    "    prior_I = cov19.model.uncorrelated_prior_I(\n",
    "        lambda_t_log=lambda_t_log,\n",
    "        mu=mu,\n",
    "        pr_median_delay=pr_delay,\n",
    "        name_I_begin=\"I_begin\",\n",
    "        name_I_begin_ratio_log=\"I_begin_ratio_log\",\n",
    "        pr_sigma_I_begin=2,\n",
    "        n_data_points_used=5,\n",
    "    )\n",
    "\n",
    "    # Use lambda_t_log and mu to run the SIR model\n",
    "    new_cases = cov19.model.SIR(\n",
    "        lambda_t_log=lambda_t_log,\n",
    "        mu=mu,\n",
    "        name_new_I_t=\"new_I_t\",\n",
    "        name_I_t=\"I_t\",\n",
    "        name_I_begin=\"I_begin\",\n",
    "        pr_I_begin=prior_I,\n",
    "    )\n",
    "\n",
    "    # Delay the cases by a lognormal reporting delay\n",
    "    \n",
    "    new_cases = cov19.model.delay_cases(\n",
    "        cases=new_cases,\n",
    "        name_cases=\"delayed_cases\",\n",
    "        name_delay=\"delay\",\n",
    "        name_width=\"delay-width\",\n",
    "        pr_mean_of_median=pr_delay,\n",
    "        pr_sigma_of_median=0.2,\n",
    "        pr_median_of_width=0.3,\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Modulate the inferred cases by a abs(sin(x)) function, to account for weekend effects\n",
    "    # Also adds the \"new_cases\" variable to the trace that has all model features.\n",
    "    new_cases = cov19.model.week_modulation(\n",
    "        cases=new_cases,\n",
    "        name_cases=\"new_cases\",\n",
    "        name_weekend_factor=\"weekend_factor\",\n",
    "        name_offset_modulation=\"offset_modulation\",\n",
    "        week_modulation_type=\"abs_sine\",\n",
    "        pr_mean_weekend_factor=0.3,\n",
    "        pr_sigma_weekend_factor=0.5,\n",
    "        weekend_days=(6, 7),\n",
    "    )\n",
    "\n",
    "    # Define the likelihood, uses the new_cases_obs set as model parameter\n",
    "    cov19.model.student_t_likelihood(new_cases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## MCMC sampling\n",
    "\n",
    "After the model is built, it is sampled using a MCMC sampler.\n",
    "The number of parallel runs can be set with the argument `cores=`.\n",
    "The sampling can take a long time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_607148/1808669946.py:2: DeprecationWarning: The module `aesara.tensor.nnet` is deprecated and will be removed from Aesara in version 2.9.0\n",
      "  import aesara.tensor.nnet\n"
     ]
    }
   ],
   "source": [
    "import pymc.sampling_jax\n",
    "import aesara.tensor.nnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function aesara.tensor.nnet.basic.relu(x, alpha=0)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.nnet.basic.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 11, 15, 17, 58, 55, 444467)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 50 samples in chain.\n",
      "WARNING  [pymc] Only 50 samples in chain.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34 µs, sys: 0 ns, total: 34 µs\n",
      "Wall time: 755 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "INFO     [pymc] Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "INFO     [pymc] Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "INFO     [pymc] Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [lambda_0_log_, lambda_1_log_, lambda_2_log_, lambda_3_log_, transient_day_1, transient_day_2, transient_day_3, transient_len_1_raw_, transient_len_2_raw_, transient_len_3_raw_, mu, I_begin_ratio_log, delay_log, weekend_factor_log, offset_modulation_rad, sigma_obs]\n",
      "INFO     [pymc] NUTS: [lambda_0_log_, lambda_1_log_, lambda_2_log_, lambda_3_log_, transient_day_1, transient_day_2, transient_day_3, transient_len_1_raw_, transient_len_2_raw_, transient_len_3_raw_, mu, I_begin_ratio_log, delay_log, weekend_factor_log, offset_modulation_rad, sigma_obs]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/600 00:00&lt;? Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time\n",
    "#idata = pm.sampling_jax.sample_numpyro_nuts(model=this_model, tune=100, draws=50)#, init=\"advi+adapt_diag\")\n",
    "pm.sample(model=this_model, tune=100, draws=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Plotting\n",
    "Plotting tools are rudimentary right now. But one can always write custom plotting function\n",
    "by accessing the samples stored in the inference data. See the arviz [documentation](https://arviz-devs.github.io/arviz/getting_started/XarrayforArviZ.html#xarray-for-arviz) for a indepth explanation of the inference data structure.\n",
    "\n",
    "### Distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 3, figsize=(6, 6.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the free Random Variables\n",
    "varnames = this_model.untransformed_freeRVs\n",
    "print(varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot them\n",
    "for i, (key, math) in enumerate(\n",
    "    # left column\n",
    "    zip([\"weekend_factor\", \"mu\", \"lambda_0\", \"lambda_1\", \"lambda_2\", \"lambda_3\"],\n",
    "    [\"\\Phi_w\",\"\\mu\",\"\\lambda_0\", \"\\lambda_1\", \"\\lambda_2\", \"\\lambda_3\"])\n",
    "):\n",
    "    cov19.plot.distribution(this_model, idata, key, ax=axes[i, 0], dist_math=math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (key, math) in enumerate(\n",
    "    # mid column\n",
    "    zip([\n",
    "        \"offset_modulation\",\n",
    "        \"sigma_obs\",\n",
    "        \"I_begin\",\n",
    "        \"transient_day_1\",\n",
    "        \"transient_day_2\",\n",
    "        \"transient_day_3\",\n",
    "    ],    [\n",
    "        \"f_w\",\n",
    "        \"\\sigma_{obs}\",\n",
    "        \"I_0\",\n",
    "        \"t_1\",\n",
    "        \"t_2\",\n",
    "        \"t_3\",\n",
    "    ])\n",
    "):\n",
    "    cov19.plot.distribution(this_model, idata, key, ax=axes[i, 1],dist_math=math,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right column\n",
    "for i, (key,math) in enumerate(\n",
    "    zip([\n",
    "        \"delay\",\n",
    "        \"transient_len_1\",\n",
    "        \"transient_len_2\",\n",
    "        \"transient_len_3\",\n",
    "    ],[\n",
    "        \"D\",\n",
    "        \"\\Delta t_1\",\n",
    "        \"\\Delta t_2\",\n",
    "        \"\\Delta t_3\"\n",
    "    ])\n",
    "):\n",
    "    cov19.plot.distribution(this_model, idata, key, ax=axes[i + 2, 2],dist_math=math,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "fig  # To print in jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Timeseries\n",
    "timeseries overview, for now needs an offset variable to get cumulative cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = cov19.plot.timeseries_overview(this_model, idata, offset=total_cases_obs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark --iversions -v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c6acc8929ce41277aa23604980fc93c5246861ffc8083657ed2c465ee07481a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
